spring:
  application:
    name: product-worker

  # R2DBC configuration for reactive PostgreSQL access
  r2dbc:
    url: r2dbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:product}
    username: ${DB_USER:product_service}
    password: ${DB_PASSWORD:changeme}
    pool:
      initial-size: 5
      max-size: 10
      max-idle-time: 30m
      max-acquire-time: 3s
      validation-query: SELECT 1

  # Redis configuration for distributed state
  data:
    redis:
      host: ${REDIS_HOST:localhost}
      port: ${REDIS_PORT:6379}
      password: ${REDIS_PASSWORD:}
      lettuce:
        pool:
          min-idle: 5
          max-active: 20
          max-wait: 3s
        shutdown-timeout: 200ms

  # Kafka consumer configuration
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    consumer:
      group-id: product-worker
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      auto-offset-reset: earliest
      enable-auto-commit: false
      max-poll-records: 100
    properties:
      schema.registry.url: ${SCHEMA_REGISTRY_URL:http://localhost:8081}
      specific.avro.reader: true

# Scheduled job configuration
scheduling:
  slot-expiration:
    fixed-delay: 60000  # Run every 1 minute
  pre-expiration-notification:
    fixed-delay: 300000  # Run every 5 minutes

# Server configuration (for management endpoints only)
server:
  port: ${PORT:8081}
  shutdown: graceful

# Actuator endpoints for health checks and metrics
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus,metrics
  endpoint:
    health:
      show-details: when-authorized
  metrics:
    export:
      prometheus:
        enabled: true

# Logging configuration
logging:
  level:
    root: INFO
    com.dopaminestore.product: DEBUG
    org.springframework.kafka: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} [%X{traceId}] - %msg%n"
